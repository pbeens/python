{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OISE AQ/ABQ Courses.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNq2ioKti+96z8ZFiJHA2HW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pbeens/python/blob/master/OISE_AQ_ABQ_Courses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpQa6ofvkGOF"
      },
      "source": [
        "This program scans all the URLs to compile a list of all AQ/ABQ courses offered by OISE, then scans each of those courses to see if they are offered in the prescribed term (see # global variables). The name and URL of each course offered that term is then stored locally in a webpage. \n",
        "\n",
        "GitHub URL: https://github.com/pbeens/python/blob/master/OISE_AQ_ABQ_Courses.ipynb\n",
        "\n",
        "Colab URL: https://colab.research.google.com/drive/18DxRzxTiDYHEOQ6ZlE4qqQO8C0_2r0t-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JkB0tWvKnBj"
      },
      "source": [
        "# imports\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKfZl25QKssU"
      },
      "source": [
        "# global variable(s)\n",
        "urls = ['https://cpl.oise.utoronto.ca/program_certificate/abq-primary-junior/',\n",
        "        'https://cpl.oise.utoronto.ca/program_certificate/abq-intermediate/',\n",
        "        'https://cpl.oise.utoronto.ca/program_certificate/abq-senior/',\n",
        "        'https://cpl.oise.utoronto.ca/program_certificate/one-session-additional-qualifications/',\n",
        "        'https://cpl.oise.utoronto.ca/program_certificate/three-session-additional-qualifications/',\n",
        "        'https://cpl.oise.utoronto.ca/program_certificate/honour-specialist/',\n",
        "        'https://cpl.oise.utoronto.ca/program_certificate/technological-education/']\n",
        "term = '2021 Late Summer'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKAAERSSKtNv"
      },
      "source": [
        "# grab each URL\n",
        "all_courses = []\n",
        "for url in urls:\n",
        "  print(f'Grabbing courses from {url}... ')\n",
        "  html_page = urllib.request.urlopen(url)\n",
        "  soup = BeautifulSoup(html_page, \"html.parser\")\n",
        "  # find all the links with /course/ in the link\n",
        "  for link in soup.findAll('a'):\n",
        "    s = str(link.get('href'))\n",
        "    if s.find('/course/') > 1:\n",
        "      all_courses.append(s)\n",
        "all_courses.sort()\n",
        "print('Done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9T_BB4-lrQ6"
      },
      "source": [
        "# warm fuzzy feeling that it grabbed all the courses\n",
        "for course in all_courses:\n",
        "  print(course)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym13-ytiK0PZ"
      },
      "source": [
        "# inspect each page for course date (Late Summer 2021 as an example)\n",
        "term_courses = {}\n",
        "for course in all_courses:\n",
        "  print(f'Processing {course}...')\n",
        "  html_page = urllib.request.urlopen(course)\n",
        "  soup = BeautifulSoup(html_page, \"html.parser\")\n",
        "  # need to do some magic to find the term text\n",
        "  divs = soup.find_all('div', {'class':'grid--auto'}) # where the term is stored\n",
        "  for div in divs:\n",
        "    if len(div.text) > 0: # skip the empty ones\n",
        "      if div.text == term:\n",
        "        # clean up the title (course name) for use in the HTML file\n",
        "        title = str(soup.title) \\\n",
        "          .replace('<title>','') \\\n",
        "          .replace(' - OISE Continuing and Professional Learning</title>','')\n",
        "        print(f'{term}: {title}') # tell us which courses were found\n",
        "        term_courses[title] = course # add to dict of term_courses\n",
        "        break # once found we can move on\n",
        "print('Done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_-n0FgithlZ"
      },
      "source": [
        "# test section to test the term_courses dict\n",
        "for (k, v) in term_courses.items():\n",
        "  print(f'{k}: {v}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0yCppW-K5zR"
      },
      "source": [
        "# create html file with desired course listings\n",
        "file = './courses.html'\n",
        "with open(file, 'w') as f:\n",
        "  s = f'''<HTML>\\n<HEAD>\\n\\t<TITLE>{term}</TITLE>\\n</HEAD>\\n<BODY>\\n'''\n",
        "  f.write(s)\n",
        "  for k, v in term_courses.items():\n",
        "    f.write(f'\\t<a href=\"{v}\">{k}</a><br>\\n')\n",
        "  s = '''</BODY>\\n<HTML>'''\n",
        "  f.write(s)\n",
        "f.close()\n",
        "print(f'{file} created.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}